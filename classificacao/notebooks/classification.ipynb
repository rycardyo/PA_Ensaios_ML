{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.tree           import DecisionTreeClassifier   as dt  \n",
    "from sklearn.linear_model   import LogisticRegression       as lr \n",
    "from sklearn.ensemble       import RandomForestClassifier   as rf \n",
    "from sklearn.neighbors      import KNeighborsClassifier     as knn\n",
    "from sklearn.preprocessing  import normalize\n",
    "from sklearn                import metrics                  as mt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class normalizer():\n",
    "\n",
    "    def __init__(self,\n",
    "                 df):\n",
    "        \n",
    "        self.dict_max = {c : df[c].max() for c in df.columns}\n",
    "\n",
    "\n",
    "    def getDfcolumnNormalized(self, \n",
    "                              df):\n",
    "        \n",
    "        df_normalized = df.copy()\n",
    "\n",
    "        for c in df.columns:\n",
    "\n",
    "            df_normalized.loc[:, c] = df_normalized.loc[:,c].apply(lambda x: x/self.dict_max[c])\n",
    "\n",
    "        return df_normalized \n",
    "    \n",
    "\n",
    "    def getDfcolumnDeNormalized(self,\n",
    "                                df):\n",
    "        \n",
    "        df_normalized = df.copy()\n",
    "\n",
    "        for c in df.columns:\n",
    "\n",
    "            df_normalized.loc[:, c] = df_normalized.loc[:,c].apply(lambda x: x*self.dict_max[c])\n",
    "\n",
    "        return df_normalized \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test      = pd.read_csv('../data/X_test.csv') \n",
    "X_training  = pd.read_csv('../data/X_training.csv')\n",
    "X_valid     = pd.read_csv('../data/X_validation.csv')\n",
    "y_test      = pd.read_csv('../data/y_test.csv')\n",
    "y_training  = pd.read_csv('../data/y_training.csv')\n",
    "y_valid     = pd.read_csv('../data/y_validation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancia um normalizador treinado com os parametros de training\n",
    "normalizer_X = normalizer(X_training)\n",
    "\n",
    "X_test_normalized   = normalizer_X.getDfcolumnNormalized(X_test)\n",
    "X_training_norm     = normalizer_X.getDfcolumnNormalized(X_training)\n",
    "X_valid_norm        = normalizer_X.getDfcolumnNormalized(X_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "class superModelClassifier():\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 principalMetric : Literal['ACCURACY', 'F1_SCORE', 'PRECISION', 'RECALL']):\n",
    "        \n",
    "        self.model = model \n",
    "\n",
    "    def fineTuning():\n",
    "        ...\n",
    "    \n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = knn()\n",
    "knn_classifier.fit(X_training_norm, y_training)\n",
    "\n",
    "\n",
    "## fine tuning baseado no validation \n",
    "n_neighbors_fine_tuning = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "class ExperimentClassification():\n",
    "\n",
    "    def __init__(self,\n",
    "                 experiment_data_context_order : list = ['training', 'test', 'valid'],\n",
    "                 training_dataset : dict = None,\n",
    "                 test_dataset     : dict = None,\n",
    "                 valid_dataset    : dict = None):\n",
    "\n",
    "        self.results = None\n",
    "        self.experiment_data_context_order = experiment_data_context_order\n",
    "\n",
    "        self.x_training = training_dataset['x']\n",
    "        self.y_training = training_dataset['y']\n",
    "\n",
    "        self.x_test = test_dataset['x']\n",
    "        self.y_test = test_dataset['y']\n",
    "        \n",
    "        self.x_valid = valid_dataset['x']\n",
    "        self.y_valid = valid_dataset['y']\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    def computeMetricsSklearnModel(self,\n",
    "                                   predictions_training,\n",
    "                                   predictions_test,\n",
    "                                   predictions_valid):\n",
    "        \n",
    "            \n",
    "            \n",
    "        # compute accuracy\n",
    "        accuracy_training   = mt.accuracy_score(self.y_training, predictions_training)\n",
    "        accuracy_test       = mt.accuracy_score(self.y_training, predictions_test)\n",
    "        accuracy_valid      = mt.accuracy_score(self.y_valid,  predictions_valid)\n",
    "        \n",
    "        #compute precision\n",
    "        precision_training  = mt.precision_score(self.y_training, predictions_valid)\n",
    "        precision_test      = mt.precision_score(self.y_test, predictions_test)\n",
    "        precision_valid     = mt.precision_score(self.y_valid, predictions_valid)\n",
    "        \n",
    "        # compute recalls\n",
    "        recall_training = mt.recall_score(X_training_norm, y_training)\n",
    "        recall_test = mt.recall_score(X_test_normalized, y_test)\n",
    "        recall_valid = mt.recall_score(X_valid_norm, y_valid)\n",
    "        \n",
    "        # compute f1_scores\n",
    "        f1_score_training = mt.f1_score(X_training_norm, y_training)\n",
    "        f1_score_test = mt.f1_score(X_test_normalized, y_test)\n",
    "        f1_score_valid = mt.f1_score(X_valid_norm, y_valid)\n",
    "    \n",
    "    def setResults(self,\n",
    "                    experimentName,\n",
    "                    accuracies,\n",
    "                    recalls,\n",
    "                    precisions, \n",
    "                    f1_scores\n",
    "                ):\n",
    "        \n",
    "            dict_accuracies  = {data_context : accuracies[idx]  for idx, data_context in enumerate(self.data_order)}\n",
    "            dict_recalls     = {data_context : recalls[idx]     for idx, data_context in enumerate(self.data_order)}\n",
    "            dict_precisions  = {data_context : precisions[idx]  for idx, data_context in enumerate(self.data_order)}  \n",
    "            dict_f1_scores   = {data_context : f1_scores[idx]   for idx, data_context in enumerate(self.data_order)}\n",
    "\n",
    "            self.results[experimentName]['metrics']  = [dict_accuracies, dict_recalls, dict_f1_scores, dict_precisions]\n",
    "\n",
    "\n",
    "\n",
    "    def fine_tuning_knn(self,\n",
    "                        parameters : list):\n",
    "        ''' \n",
    "        dict_results : \n",
    "            model : model, \n",
    "            metrics : \n",
    "                training : \n",
    "                    accuracy \n",
    "                    precision\n",
    "                    recall\n",
    "                    f1_score\n",
    "                test :  \n",
    "                    ... \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        dict_results = {\n",
    "\n",
    "        }\n",
    "        \n",
    "        \n",
    "        for k in parameters:\n",
    "            experimentName = f'k_neighbors_{k}'\n",
    "            currentResult = {}\n",
    "            \n",
    "            accuracies  = []\n",
    "            precisions  = []\n",
    "            recalls     = []\n",
    "            predictions = []\n",
    "            f1_scores   = []\n",
    "            \n",
    "\n",
    "            knn_classifier = knn(k)\n",
    "            \n",
    "            knn_classifier.fit(self.x_training, \n",
    "                               self.y_training)\n",
    "            \n",
    "            \n",
    "            predictions_training = knn_classifier.predict(self.x_training)\n",
    "            predictions_test     = knn_classifier.predict(self.x_test)\n",
    "            predictions_valid    = knn_classifier.predict(self.x_valid)\n",
    "\n",
    "                    \n",
    "            \n",
    "           self.setResults(\n",
    "                           precitions = predictions\n",
    "                           experimentName   = experimentName,\n",
    "                           accuracies       = accuracies,\n",
    "                           precisions       = precisions, \n",
    "                           recalls          = recalls, \n",
    "                           f1_scores        = f1_scores\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Model Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
