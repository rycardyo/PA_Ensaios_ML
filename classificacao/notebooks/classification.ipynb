{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.tree           import DecisionTreeClassifier   as dt  \n",
    "from sklearn.linear_model   import LogisticRegression       as lr \n",
    "from sklearn.ensemble       import RandomForestClassifier   as rf \n",
    "from sklearn.tree           import DecisionTreeClassifier   as dt\n",
    "from sklearn.neighbors      import KNeighborsClassifier     as knn\n",
    "from sklearn.preprocessing  import normalize\n",
    "from sklearn                import metrics                  as mt \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class normalizer():\n",
    "\n",
    "    def __init__(self,\n",
    "                 df):\n",
    "        \n",
    "        self.dict_max = {c : df[c].max() for c in df.columns}\n",
    "\n",
    "\n",
    "    def getDfcolumnNormalized(self, \n",
    "                              df):\n",
    "        \n",
    "        df_normalized = df.copy()\n",
    "\n",
    "        for c in df.columns:\n",
    "\n",
    "            df_normalized.loc[:, c] = df_normalized.loc[:,c].apply(lambda x: x/self.dict_max[c])\n",
    "\n",
    "        return df_normalized \n",
    "    \n",
    "\n",
    "    def getDfcolumnDeNormalized(self,\n",
    "                                df):\n",
    "        \n",
    "        df_normalized = df.copy()\n",
    "\n",
    "        for c in df.columns:\n",
    "\n",
    "            df_normalized.loc[:, c] = df_normalized.loc[:,c].apply(lambda x: x*self.dict_max[c])\n",
    "\n",
    "        return df_normalized \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test      = pd.read_csv('../data/X_test.csv') \n",
    "X_training  = pd.read_csv('../data/X_training.csv')\n",
    "X_valid     = pd.read_csv('../data/X_validation.csv')\n",
    "y_test      = pd.read_csv('../data/y_test.csv')\n",
    "y_training  = pd.read_csv('../data/y_training.csv')\n",
    "y_valid     = pd.read_csv('../data/y_validation.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancia um normalizador treinado com os parametros de training\n",
    "normalizer_X = normalizer(X_training)\n",
    "\n",
    "X_test_normalized   = normalizer_X.getDfcolumnNormalized(X_test)\n",
    "X_training_norm     = normalizer_X.getDfcolumnNormalized(X_training)\n",
    "X_valid_norm        = normalizer_X.getDfcolumnNormalized(X_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "class superModelClassifier():\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 principalMetric : Literal['ACCURACY', 'F1_SCORE', 'PRECISION', 'RECALL']):\n",
    "        \n",
    "        self.model = model \n",
    "\n",
    "    def fineTuning():\n",
    "        ...\n",
    "    \n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p123/.local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "knn_classifier = knn()\n",
    "knn_classifier.fit(X_training_norm, y_training)\n",
    "\n",
    "\n",
    "## fine tuning baseado no validation \n",
    "n_neighbors_fine_tuning = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "class ExperimentClassification():\n",
    "\n",
    "    def __init__(self,\n",
    "                 training_dataset : dict = None,\n",
    "                 test_dataset     : dict = None,\n",
    "                 valid_dataset    : dict = None):\n",
    "\n",
    "\n",
    "        self.general_metrics = []\n",
    "\n",
    "        self.x_training = training_dataset['x']\n",
    "        self.y_training = training_dataset['y']\n",
    "\n",
    "        self.x_test = test_dataset['x']\n",
    "        self.y_test = test_dataset['y']\n",
    "        \n",
    "        self.x_valid = valid_dataset['x']\n",
    "        self.y_valid = valid_dataset['y']\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    def computeMetricsSklearnModel(self,\n",
    "                                   predictions_training,\n",
    "                                   predictions_test,\n",
    "                                   predictions_valid) -> dict:\n",
    "\n",
    "        '''\n",
    "        returns:\n",
    "            metrics :{\n",
    "                accuracy    : dict['training','test','valid'], \n",
    "                precision   : dict['training','test','valid'],\n",
    "                recall      : dict['training','test','valid'],\n",
    "                f1_score    : dict['training','test','valid']\n",
    "            }\n",
    "        \n",
    "        '''        \n",
    "            \n",
    "        accuracies  = { \n",
    "                        'training'  : None,\n",
    "                        'test'      : None,\n",
    "                        'valid'     : None\n",
    "                       }\n",
    "        \n",
    "        precisions  = {\n",
    "                        'training'  : None,\n",
    "                        'test'      : None,\n",
    "                        'valid'     : None\n",
    "        }\n",
    "        recalls     = {\n",
    "                        'training'  : None,\n",
    "                        'test'      : None,\n",
    "                        'valid'     : None}\n",
    "        \n",
    "        f1_scores   = {\n",
    "                        'training'  : None,\n",
    "                        'test'      : None,\n",
    "                        'valid'     : None\n",
    "        }    \n",
    "        \n",
    "\n",
    "        # compute accuracy\n",
    "        accuracies['training']   = mt.accuracy_score(self.y_training, predictions_training)\n",
    "        accuracies['test']       = mt.accuracy_score(self.y_test, predictions_test)\n",
    "        accuracies['valid']      = mt.accuracy_score(self.y_valid,  predictions_valid)\n",
    "        \n",
    "        #compute precision\n",
    "        precisions['training']  = mt.precision_score(self.y_training, predictions_training)\n",
    "        precisions['test']      = mt.precision_score(self.y_test, predictions_test)\n",
    "        precisions['valid']     = mt.precision_score(self.y_valid, predictions_valid)\n",
    "        \n",
    "        # compute recalls\n",
    "        recalls['training']     = mt.recall_score(self.y_training, predictions_training)\n",
    "        recalls['test']         = mt.recall_score(self.y_test, predictions_test)\n",
    "        recalls['valid']        = mt.recall_score(self.y_valid, predictions_valid)\n",
    "        \n",
    "        # compute f1_scores\n",
    "        f1_scores['training']   = mt.f1_score(self.y_training, predictions_training)\n",
    "        f1_scores['test']       = mt.f1_score(self.y_test, predictions_test)\n",
    "        f1_scores['valid']      = mt.f1_score(self.y_valid, predictions_valid)\n",
    "\n",
    "\n",
    "        metrics = {\n",
    "             'accuracy'  : accuracies,\n",
    "             'precision' : precisions,\n",
    "             'recall'    : recalls, \n",
    "             'f1_score'  : f1_scores\n",
    "        }\n",
    "\n",
    "        return metrics \n",
    "\n",
    "    def setResults(self,\n",
    "                    experimentName,\n",
    "                    accuracies,\n",
    "                    recalls,\n",
    "                    precisions, \n",
    "                    f1_scores\n",
    "                ):\n",
    "        \n",
    "            dict_accuracies  = {data_context : accuracies[idx]  for idx, data_context in enumerate(self.data_order)}\n",
    "            dict_recalls     = {data_context : recalls[idx]     for idx, data_context in enumerate(self.data_order)}\n",
    "            dict_precisions  = {data_context : precisions[idx]  for idx, data_context in enumerate(self.data_order)}  \n",
    "            dict_f1_scores   = {data_context : f1_scores[idx]   for idx, data_context in enumerate(self.data_order)}\n",
    "\n",
    "            self.results[experimentName]['metrics']  = [dict_accuracies, dict_recalls, dict_f1_scores, dict_precisions]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class experimentKnn(ExperimentClassification):\n",
    "\n",
    "    def __init__(self,\n",
    "                 k_neigbhors : list,\n",
    "                 training_dataset : dict = None,\n",
    "                 test_dataset     : dict = None,\n",
    "                 valid_dataset    : dict = None,\n",
    "                 verbose          : bool = True,\n",
    "                 experimentName   : str = 'Experimento'\n",
    "                 ):\n",
    "        \n",
    "        super().__init__(training_dataset,\n",
    "                 test_dataset,\n",
    "                 valid_dataset)\n",
    "        \n",
    "        self.parameters = k_neigbhors\n",
    "        self.experimentName = experimentName\n",
    "        self.verbose        = verbose \n",
    "\n",
    "\n",
    "    def log(self,\n",
    "            message: str):\n",
    "        \n",
    "        print('='*45)\n",
    "        print(f'{self.experimentName} : {message}')\n",
    "        print('='*45)\n",
    "        \n",
    "\n",
    "    def fine_tuning_knn(self):\n",
    "        ''' \n",
    "        dict_results : \n",
    "            model : model, \n",
    "            metrics : \n",
    "                training : \n",
    "                    accuracy \n",
    "                    precision\n",
    "                    recall\n",
    "                    f1_score\n",
    "                test :  \n",
    "                    ... \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        dict_results = {\n",
    "\n",
    "        }\n",
    "        \n",
    "        \n",
    "        for k in tqdm(self.parameters):\n",
    "            experimentName = f'k_neighbors_{k}'\n",
    "            currentResult = {}\n",
    "            \n",
    "           \n",
    "            knn_classifier = knn(k)\n",
    "            \n",
    "            knn_classifier.fit(self.x_training, \n",
    "                               self.y_training)\n",
    "            \n",
    "            \n",
    "            predictions_training = knn_classifier.predict(self.x_training)\n",
    "            predictions_test     = knn_classifier.predict(self.x_test)\n",
    "            predictions_valid    = knn_classifier.predict(self.x_valid)\n",
    "\n",
    "            # calcula as principais metricas do modelo\n",
    "            metrics = self.computeMetricsSklearnModel(\n",
    "                                                        predictions_training=predictions_training, \n",
    "                                                        predictions_test=predictions_test, \n",
    "                                                        predictions_valid=predictions_valid\n",
    "                                                    )\n",
    "                    \n",
    "            self.general_metrics.append(metrics)\n",
    "\n",
    "            if self.verbose:\n",
    "                #self.log(f\"Acurácia com k = {k}: \\n {metrics['accuracy']} %\" )\n",
    "                \n",
    "                self.log(f\"F1 Scre com k = {k}: \\n {metrics['f1_score']} %\")\n",
    "                \n",
    "\n",
    "        \n",
    "        return self.general_metrics\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/p123/.local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "  0%|          | 0/10 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n\u001b[1;32m     12\u001b[0m valid_dataset \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m : X_valid_norm, \n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m : y_valid\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     18\u001b[0m experimento_knn \u001b[38;5;241m=\u001b[39m experimentKnn(k_neigbhors\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m     19\u001b[0m                                 training_dataset\u001b[38;5;241m=\u001b[39mtraining_dataset,\n\u001b[1;32m     20\u001b[0m                                 test_dataset\u001b[38;5;241m=\u001b[39mtest_dataset, \n\u001b[1;32m     21\u001b[0m                                 valid_dataset\u001b[38;5;241m=\u001b[39mvalid_dataset\n\u001b[1;32m     22\u001b[0m                                 )\n\u001b[0;32m---> 24\u001b[0m resultados \u001b[38;5;241m=\u001b[39m \u001b[43mexperimento_knn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tuning_knn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m resultados[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[8], line 60\u001b[0m, in \u001b[0;36mexperimentKnn.fine_tuning_knn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m knn_classifier \u001b[38;5;241m=\u001b[39m knn(k)\n\u001b[1;32m     56\u001b[0m knn_classifier\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_training, \n\u001b[1;32m     57\u001b[0m                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_training)\n\u001b[0;32m---> 60\u001b[0m predictions_training \u001b[38;5;241m=\u001b[39m \u001b[43mknn_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_training\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m predictions_test     \u001b[38;5;241m=\u001b[39m knn_classifier\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test)\n\u001b[1;32m     62\u001b[0m predictions_valid    \u001b[38;5;241m=\u001b[39m knn_classifier\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_valid)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:295\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, classes_k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes_):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m         mode, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_y\u001b[49m\u001b[43m[\u001b[49m\u001b[43mneigh_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m         mode, _ \u001b[38;5;241m=\u001b[39m weighted_mode(_y[neigh_ind, k], weights, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/fixes.py:124\u001b[0m, in \u001b[0;36m_mode\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mode\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sp_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m parse_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.9.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 124\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sp_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m parse_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.10.999\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    126\u001b[0m             \u001b[38;5;66;03m# scipy.stats.mode has changed returned array shape with axis=None\u001b[39;00m\n\u001b[1;32m    127\u001b[0m             \u001b[38;5;66;03m# and keepdims=True, see https://github.com/scipy/scipy/pull/17561\u001b[39;00m\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:603\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result_to_tuple(hypotest_fun_out(\u001b[38;5;241m*\u001b[39msamples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m    602\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(x, axis, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 603\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypotest_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m res \u001b[38;5;241m=\u001b[39m _add_reduced_axes(res, reduced_axes, keepdims)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tuple_to_result(\u001b[38;5;241m*\u001b[39mres)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/shape_base.py:402\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m buff[ind0] \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[0;32m--> 402\u001b[0m     buff[ind] \u001b[38;5;241m=\u001b[39m asanyarray(\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, matrix):\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# wrap the array, to preserve subclasses\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     buff \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39m__array_wrap__(buff)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:595\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper.<locals>.hypotest_fun\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhypotest_fun\u001b[39m(x):\n\u001b[0;32m--> 595\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[43m)\u001b[49m[:n_samp\u001b[38;5;241m+\u001b[39mn_kwd_samp]\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sentinel:\n\u001b[1;32m    597\u001b[0m         samples \u001b[38;5;241m=\u001b[39m _remove_sentinel(samples, paired, sentinel)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/shape_base.py:866\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m N \u001b[38;5;241m%\u001b[39m sections:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    865\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray split does not result in an equal division\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_or_sections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/shape_base.py:782\u001b[0m, in \u001b[0;36marray_split\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    780\u001b[0m     st \u001b[38;5;241m=\u001b[39m div_points[i]\n\u001b[1;32m    781\u001b[0m     end \u001b[38;5;241m=\u001b[39m div_points[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 782\u001b[0m     sub_arys\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mst\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sub_arys\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:533\u001b[0m, in \u001b[0;36m_swapaxes_dispatcher\u001b[0;34m(a, axis1, axis2)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument 1 must be numpy.ndarray, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{name}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(a)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m put(ind, v, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_swapaxes_dispatcher\u001b[39m(a, axis1, axis2):\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[1;32m    537\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_swapaxes_dispatcher)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mswapaxes\u001b[39m(a, axis1, axis2):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_dataset = {\n",
    "    'x' : X_training_norm, \n",
    "    'y' : y_training\n",
    "}\n",
    "\n",
    "test_dataset = {\n",
    "    'x' : X_test_normalized, \n",
    "    'y' : y_test\n",
    "}\n",
    "\n",
    "\n",
    "valid_dataset = {\n",
    "    'x' : X_valid_norm, \n",
    "    'y' : y_valid\n",
    "}\n",
    "\n",
    "\n",
    "experimento_knn = experimentKnn(k_neigbhors=[1,2,3,4,5,6,7,8,9,10],\n",
    "                                training_dataset=training_dataset,\n",
    "                                test_dataset=test_dataset, \n",
    "                                valid_dataset=valid_dataset\n",
    "                                )\n",
    "\n",
    "resultados = experimento_knn.fine_tuning_knn()\n",
    "resultados[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Arvores de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 - DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.9275807584269663\n",
      "accuracy: 1.0\n",
      "accuracy: 0.9362762136484765\n",
      "precision: 0.9253875120413346\n",
      "recall: 0.9297844258688958\n"
     ]
    }
   ],
   "source": [
    "decisionTreeModel = dt(\n",
    "    max_features='sqrt',\n",
    "    max_depth=None,  # None means no limit on depth\n",
    "    min_samples_leaf=1\n",
    "    #max_depth=\n",
    ")\n",
    "\n",
    "decisionTreeModel.fit(X_training_norm, y_training)\n",
    "predictions = decisionTreeModel.predict(X_test_normalized)\n",
    "predictions_training = decisionTreeModel.predict(X_training_norm)\n",
    "\n",
    "f1_dt = mt.f1_score(y_test, predictions)\n",
    "acc_dt = mt.accuracy_score(y_test, predictions)\n",
    "acc_tr_dt = mt.accuracy_score(y_training, predictions_training)\n",
    "pre_dt = mt.precision_score(y_test, predictions)\n",
    "rec_dt = mt.recall_score(y_test, predictions)\n",
    "\n",
    "print(f'f1_score: {f1_dt}')\n",
    "print(f'accuracy: {acc_tr_dt}')\n",
    "print(f'accuracy: {acc_dt}')\n",
    "\n",
    "print(f'precision: {pre_dt}')\n",
    "print(f'recall: {rec_dt}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 - RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p123/.local/lib/python3.10/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc training: 0.9967317106805489\n",
      "acc: 0.9632333062989997\n",
      "f1: 0.9575568435131521\n",
      "precision: 0.9705377315860823\n",
      "recall: 0.944918609766828\n"
     ]
    }
   ],
   "source": [
    "# max-feature = uma random forest é uma combinação de várias árvores de decisão, geradas baseadas em bootstrapping, para amostragem de cada \n",
    "# nova subarvore. esta metodologia busca evitar o overfitting,\n",
    "#  pois cada arvore é gerada com uma amostra diferente dos dados, a quantidade de dados sera definido pelo max_samples. \n",
    "# \n",
    "# max_featres: a cada nova ramificação da arvore, \n",
    "# o modelo irá considerar apenas uma fração dos atributos disponíveis, para calculo da função de custo, e avaliar sob qual feature realizar a separação. \n",
    "\n",
    "randomForestModel = rf(\n",
    "                        n_estimators = 100,\n",
    "                        max_features = 'sqrt',\n",
    "                        bootstrap    = True, \n",
    "                        max_samples  = 0.6 ,\n",
    "                        n_jobs       = -1\n",
    "                       )\n",
    "\n",
    "randomForestModel.fit(X_training_norm, y_training)\n",
    "predictions_test  = randomForestModel.predict(X_test_normalized)\n",
    "predictions_training = randomForestModel.predict(X_training_norm)\n",
    "#predictions_valid = randomForestModel.predict(X_test_normalized)\n",
    "\n",
    "\n",
    "accuracy = mt.accuracy_score(y_test, predictions_test)\n",
    "accuracy_training = mt.accuracy_score(y_training, predictions_training)\n",
    "\n",
    "f1_score  = mt.f1_score(y_test, predictions_test)\n",
    "precision = mt.precision_score(y_test, predictions_test)\n",
    "recall = mt.recall_score(y_test, predictions_test)\n",
    "\n",
    "print(f'acc training: {(accuracy_training)}')\n",
    "print(f'acc: {(accuracy)}')\n",
    "\n",
    "print(f'f1: {(f1_score)}')\n",
    "print(f'precision: {(precision)}')\n",
    "print(f'recall: {(recall)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Model Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
